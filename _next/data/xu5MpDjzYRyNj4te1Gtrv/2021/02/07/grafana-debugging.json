{"pageProps":{"post":{"id":6,"assetRoot":"2021/02/07/grafana-debugging","thumbnail":null,"title":"Taking pictures with Kubernetes and debugging it with Grafana","description":"A case of mistaken causes","slug":"grafana-debugging","date":"2021-02-07T10:37:00.000Z","content":"<p>A 7-node server cluster would be terrible to monitor if you had to SSH and <code>top</code> every individual node. Thankfully, that’s where Grafana and Prometheus come in to save the day.</p>\n<!-- excerpt -->\n<img src=\"/_/2021/02/07/grafana-debugging/everything-dashboard.png\" alt=\"What my Grafana dashboard currently looks like. Resist... the... urge... to... make... &#x22;Look at this graph&#x22;... references...\">\n<h2 id=\"deploying-my-monitoring-and-redeploying-my-logging\">Deploying my monitoring and redeploying my logging</h2>\n<p>After much finagling with Kubernetes manifests and general pain, I learned about <a href=\"https://helm.sh/\">Helm Charts</a>, which is essentially a package manager for Kubernetes. I have a <a href=\"https://github.com/roboll/helmfile\">Helmfile</a> set up to essentially declaratively deploy my Charts, as well.</p>\n<p>So, I got Prometheus and Grafana set up using the <a href=\"https://github.com/prometheus-community/helm-charts/tree/main/charts/kube-prometheus-stack\"><code>prometheus-community/kube-prometheus-stack</code></a> helm chart, which bundles all the metrics stuff together into one nice package. I also redeployed my logging stack using the <a href=\"https://github.com/bitnami/charts/tree/master/bitnami/fluentd/\"><code>bitnami/fluentd</code></a>, <a href=\"https://github.com/fluent/helm-charts\"><code>fluent/fluent-bit</code></a>, <a href=\"https://github.com/elastic/helm-charts/tree/master/elasticsearch\"><code>elastic/elasticsearch</code></a>, and <a href=\"https://github.com/elastic/helm-charts/tree/master/kibana\"><code>elastic/kibana</code></a>.</p>\n<img src=\"/_/2021/02/07/grafana-debugging/a29f29b47d40ccba85837d0a490a153f282597ca.svg\" title=\"&#x60;dot&#x60; image\">\n<p>Here’s a small chart demonstrating how my full monitoring stack works.</p>\n<p>A log might go through the following process:</p>\n<ol>\n<li>The container writes a log to stdout or stderr, or systemd produces a log.</li>\n<li>Every node runs Fluent-bit, which is a very lightweight log forwarder. Fluent-bit just reads every container’s output, does very minimal parsing of the log, gives it a tag (in the form of <code>kube.infra.&#x3C;namespace_name>.&#x3C;pod_name>.&#x3C;container_name></code>), and sends it off to the central Fluentd aggregation service.</li>\n<li>Fluentd receives logs from Fluent-bit and turns them into JSON based on predefined rules. So far, I have processing set up for Nginx and Kibana. Then, Fluentd writes the data to Elasticsearch.</li>\n<li>Finally, I can read the logs from Elasticsearch using Kibana or Grafana, depending on my mood, though it’s usually Kibana.</li>\n</ol>\n<p>Metrics data is slightly different.</p>\n<ol>\n<li>A node exporter app runs on every node, reading CPU, load, memory, and other fun metrics, and exposes it as a HTTP server.</li>\n<li>Every 10 seconds, Prometheus scrapes this data from all the nodes’ exporters and stores it on disk.</li>\n<li>Finally, I can look at the cool graphs that Grafana produces from this data stored in Prometheus.</li>\n</ol>\n<h2 id=\"kaap-kubernetes-as-a-paparazza\">KaaP: Kubernetes as a Paparazza</h2>\n<p>This is it! I’m finally running <em>something</em> on this godforsaken cluster!</p>\n<p>At the last <a href=\"https://indieweb.org/Homebrew_Website_Club\">IndieWeb Homebrew Website Club (HWC)</a> I attended, someone suggested to me that I could somehow have a live feed of my 3D printer. Although I can’t have a <em>live</em> feed because I have a slow internet connection, I can take a picture every few minutes and upload it to my server.</p>\n<p>So, I added a new endpoint to my API server, then wrote a <a href=\"https://github.com/astralbijection/printer_image_snapper\">small script</a> that does exactly that. It scrapes data from my OctoPrint instance’s API, snaps a picture from the exposed MJPG-streamer endpoint, and sends a PATCH request to my API server with all the information. I <a href=\"https://hub.docker.com/repository/docker/astridyu/printer_image_snapper\">Dockerized it</a> using <code>python3.9-alpine</code> for minimum image size, and created a CronJob for my cluster that runs the script every 10 minutes:<sup id=\"fnref-1\"><a href=\"#fn-1\" class=\"footnote-ref\">1</a></sup></p>\n<div class=\"remark-highlight\"><pre class=\"language-yaml\"><code class=\"language-yaml\"><span class=\"token key atrule\">apiVersion</span><span class=\"token punctuation\">:</span> v1\n<span class=\"token key atrule\">kind</span><span class=\"token punctuation\">:</span> Namespace\n<span class=\"token key atrule\">metadata</span><span class=\"token punctuation\">:</span>\n  <span class=\"token key atrule\">name</span><span class=\"token punctuation\">:</span> printer<span class=\"token punctuation\">-</span>image<span class=\"token punctuation\">-</span>snapper\n<span class=\"token punctuation\">---</span>\n<span class=\"token key atrule\">apiVersion</span><span class=\"token punctuation\">:</span> batch/v1beta1\n<span class=\"token key atrule\">kind</span><span class=\"token punctuation\">:</span> CronJob\n<span class=\"token key atrule\">metadata</span><span class=\"token punctuation\">:</span>\n  <span class=\"token key atrule\">name</span><span class=\"token punctuation\">:</span> printer<span class=\"token punctuation\">-</span>image<span class=\"token punctuation\">-</span>snapper\n  <span class=\"token key atrule\">namespace</span><span class=\"token punctuation\">:</span> printer<span class=\"token punctuation\">-</span>image<span class=\"token punctuation\">-</span>snapper\n<span class=\"token key atrule\">spec</span><span class=\"token punctuation\">:</span>\n  <span class=\"token key atrule\">schedule</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"*/10 * * * *\"</span>\n  <span class=\"token key atrule\">jobTemplate</span><span class=\"token punctuation\">:</span>\n    <span class=\"token key atrule\">spec</span><span class=\"token punctuation\">:</span>\n      <span class=\"token key atrule\">template</span><span class=\"token punctuation\">:</span>\n        <span class=\"token key atrule\">spec</span><span class=\"token punctuation\">:</span>\n          <span class=\"token key atrule\">affinity</span><span class=\"token punctuation\">:</span>\n            <span class=\"token key atrule\">nodeAffinity</span><span class=\"token punctuation\">:</span>\n              <span class=\"token key atrule\">requiredDuringSchedulingIgnoredDuringExecution</span><span class=\"token punctuation\">:</span>\n                <span class=\"token key atrule\">nodeSelectorTerms</span><span class=\"token punctuation\">:</span>\n                  <span class=\"token punctuation\">-</span> <span class=\"token key atrule\">matchExpressions</span><span class=\"token punctuation\">:</span>\n                      <span class=\"token punctuation\">-</span> <span class=\"token key atrule\">key</span><span class=\"token punctuation\">:</span> kubernetes.io/arch\n                        <span class=\"token key atrule\">operator</span><span class=\"token punctuation\">:</span> In\n                        <span class=\"token key atrule\">values</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">[</span>amd64<span class=\"token punctuation\">]</span>\n          <span class=\"token key atrule\">containers</span><span class=\"token punctuation\">:</span>\n            <span class=\"token punctuation\">-</span> <span class=\"token key atrule\">name</span><span class=\"token punctuation\">:</span> printer<span class=\"token punctuation\">-</span>image<span class=\"token punctuation\">-</span>snapper\n              <span class=\"token key atrule\">image</span><span class=\"token punctuation\">:</span> astridyu/printer_image_snapper<span class=\"token punctuation\">:</span>latest\n              <span class=\"token key atrule\">imagePullPolicy</span><span class=\"token punctuation\">:</span> Always\n              <span class=\"token key atrule\">env</span><span class=\"token punctuation\">:</span>\n                <span class=\"token punctuation\">-</span> <span class=\"token key atrule\">name</span><span class=\"token punctuation\">:</span> SNAPSHOT_URL\n                  <span class=\"token key atrule\">value</span><span class=\"token punctuation\">:</span> http<span class=\"token punctuation\">:</span>//192.168.1.73/webcam/<span class=\"token punctuation\">?</span>action=snapshot\n                <span class=\"token punctuation\">-</span> <span class=\"token key atrule\">name</span><span class=\"token punctuation\">:</span> PRINTER_ENDPOINT\n                  <span class=\"token key atrule\">value</span><span class=\"token punctuation\">:</span> https<span class=\"token punctuation\">:</span>//api.astrid.tech/api/3dprinter/1/\n                <span class=\"token punctuation\">-</span> <span class=\"token key atrule\">name</span><span class=\"token punctuation\">:</span> OCTOPRINT_ROOT\n                  <span class=\"token key atrule\">value</span><span class=\"token punctuation\">:</span> http<span class=\"token punctuation\">:</span>//192.168.1.73/\n              <span class=\"token key atrule\">envFrom</span><span class=\"token punctuation\">:</span>\n                <span class=\"token punctuation\">-</span> <span class=\"token key atrule\">secretRef</span><span class=\"token punctuation\">:</span>\n                    <span class=\"token key atrule\">name</span><span class=\"token punctuation\">:</span> printer<span class=\"token punctuation\">-</span>image<span class=\"token punctuation\">-</span>snapper\n          <span class=\"token key atrule\">restartPolicy</span><span class=\"token punctuation\">:</span> OnFailure\n</code></pre></div>\n<p>I deployed it and found that my script was broken. However, I was tired, so I just went to bed.</p>\n<h2 id=\"debugging-time\">Debugging time</h2>\n<p>When I woke up the next morning on Wednesday, I saw the weirdest thing happen on Grafana.</p>\n<img src=\"/_/2021/02/07/grafana-debugging/repeated-spikes.png\" alt=\"What&#x27;s with these spikes?\">\n<p>There were these strange, very noticeable spikes in memory consumption every few minutes. Worse, they seemed to be 1 GB tall!</p>\n<img src=\"/_/2021/02/07/grafana-debugging/1gb-spikes.png\" alt=\"One jiggabyte tall!\">\n<p>How bad could my Docker image be? It runs Python, which isn’t exactly a lightweight runtime, but it wouldn’t be 1 GB either. It stores a very low-res JPEG of my printer in RAM, probably at most 30 KB, and it doesn’t send much extra data.</p>\n<p>My mom’s old laptop was also running at 18 load (it has 4 cores, mind you) because Elasticsearch got assigned to it, but I didn’t pay it much mind.</p>\n<img src=\"/_/2021/02/07/grafana-debugging/massive-load.png\" alt=\"what the fuck\">\n<p>I continued debugging my script that afternoon, checking for, well, honestly, I don’t know what would be causing it. In a stroke of bad luck, Docker Hub happened to be freaking out on that day/week and taking extremely long on my builds, and not because I wrote inefficient code. Here’s an image from my <a href=\"https://hub.docker.com/repository/docker/astridyu/astrid_tech_api\">API server’s repository</a>. Yes, those are 177-minute queue times and 252-minute build times. But that had nothing to do with my problem, it only made debugging and testing cycles harder.</p>\n<img src=\"/_/2021/02/07/grafana-debugging/long-build-times.png\" alt=\"what the actual fuck\">\n<p>I did eventually get the script working (see the second image <a href=\"https://astrid.tech/projects/quadfrost-leds/\">here</a> for now, but I will make a dedicated page for it eventually).</p>\n<p>Then, after demoing my printer images it during the HWC meeting, I remembered: there was one Elasticsearch pod that was always crashing because it kept going OOM on my mom’s old laptop, wasn’t it? So, I added a new graph to my dashboard called “Poorly-Terminated Containers.” It’s a heatmap of container terminations that aren’t because of <code>Completed</code>.</p>\n<img src=\"/_/2021/02/07/grafana-debugging/poorly-terminated-containers.png\" alt=\"It&#x27;s like a shitty spectrogram!\">\n<p>According to this graph, my printer paparazza stopped crashing halfway through the afternoon when I fixed it, but my logging namespace continued doing so.</p>\n<img src=\"/_/2021/02/07/grafana-debugging/correlation-time.png\" alt=\"It&#x27;s a crash spectrogram!\">\n<p>And sure enough, every one of these crashes seems to correspond with that 1GB drop in memory usage.</p>\n<p>Yeah, it’s Elasticsearch being too damn big and getting killed for it.</p>\n<h2 id=\"what-now\">What now?</h2>\n<p>I tried tweaking Elasticsearch a bit, maybe running it on my Raspberry Pis instead, but I wasn’t able to really do much. So, I shut it down and freed up 2.5 GB of memory across my entire cluster, which is 1/3 of what I use in total. Given that my cluster is composed of very small and low-powered devices, I don’t think Elasticsearch is a very good option for me. I’ll have to look into more lightweight logging systems. I’ve heard Loki is a good option, and there is a Fluentd plugin for it.</p>\n<div class=\"footnotes\">\n<hr>\n<ol>\n<li id=\"fn-1\">Yes, I know this can be run on a normal server with a normal cronjob. I just wanted to try something new and give my cluster a purpose, okay?<a href=\"#fnref-1\" class=\"footnote-backref\">↩</a></li>\n</ol>\n</div>","tags":["/projects/plebscale/","/projects/quadfrost-leds/","devops","grafana","kubernetes"]}},"__N_SSG":true}